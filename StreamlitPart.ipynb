{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "StreamlitPart",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit -q"
      ],
      "metadata": {
        "id": "OWRA1cHIVa2g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c14c224-e359-4771-8aff-0621e0dd9437"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 9.1 MB 27.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 181 kB 56.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.3 MB 55.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 78 kB 8.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 235 kB 68.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 164 kB 70.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 63 kB 2.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 132 kB 73.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 793 kB 62.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 423 kB 63.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 132 kB 75.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 381 kB 66.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 51 kB 8.4 MB/s \n",
            "\u001b[?25h  Building wheel for validators (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "nbclient 0.6.6 requires traitlets>=5.2.2, but you have traitlets 5.1.1 which is incompatible.\n",
            "jupyter-console 5.2.0 requires prompt-toolkit<2.0.0,>=1.0.0, but you have prompt-toolkit 3.0.30 which is incompatible.\n",
            "google-colab 1.0.0 requires ipykernel~=4.10, but you have ipykernel 6.15.1 which is incompatible.\n",
            "google-colab 1.0.0 requires ipython~=5.5.0, but you have ipython 7.34.0 which is incompatible.\n",
            "google-colab 1.0.0 requires tornado~=5.1.0, but you have tornado 6.2 which is incompatible.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "vfUkcMeXwHNC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a42a8f91-598c-49a1-f5b7-7fcc7a075106"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install segmentation-models-pytorch"
      ],
      "metadata": {
        "id": "vCTDYQVosTtL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19c0ddd3-19c8-4985-af70-72431341b6ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting segmentation-models-pytorch\n",
            "  Downloading segmentation_models_pytorch-0.3.0-py3-none-any.whl (97 kB)\n",
            "\u001b[K     |████████████████████████████████| 97 kB 7.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from segmentation-models-pytorch) (7.1.2)\n",
            "Collecting pretrainedmodels==0.7.4\n",
            "  Downloading pretrainedmodels-0.7.4.tar.gz (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 9.1 MB/s \n",
            "\u001b[?25hCollecting timm==0.4.12\n",
            "  Downloading timm-0.4.12-py3-none-any.whl (376 kB)\n",
            "\u001b[K     |████████████████████████████████| 376 kB 61.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torchvision>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from segmentation-models-pytorch) (0.13.1+cu113)\n",
            "Collecting efficientnet-pytorch==0.7.1\n",
            "  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from segmentation-models-pytorch) (4.64.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (1.12.1+cu113)\n",
            "Collecting munch\n",
            "  Downloading munch-2.5.0-py2.py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (4.1.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.5.0->segmentation-models-pytorch) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.5.0->segmentation-models-pytorch) (2.23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from munch->pretrainedmodels==0.7.4->segmentation-models-pytorch) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (3.0.4)\n",
            "Building wheels for collected packages: efficientnet-pytorch, pretrainedmodels\n",
            "  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16446 sha256=2b26de01ba28ab994e0670081eb8e219ee6fe9a1caa4892b29ead1065907705b\n",
            "  Stored in directory: /root/.cache/pip/wheels/0e/cc/b2/49e74588263573ff778da58cc99b9c6349b496636a7e165be6\n",
            "  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pretrainedmodels: filename=pretrainedmodels-0.7.4-py3-none-any.whl size=60965 sha256=415b1139e767c26f27f9181ab4eecdc6d125a7121109f4eca90cd76ac16bb4e8\n",
            "  Stored in directory: /root/.cache/pip/wheels/ed/27/e8/9543d42de2740d3544db96aefef63bda3f2c1761b3334f4873\n",
            "Successfully built efficientnet-pytorch pretrainedmodels\n",
            "Installing collected packages: munch, timm, pretrainedmodels, efficientnet-pytorch, segmentation-models-pytorch\n",
            "Successfully installed efficientnet-pytorch-0.7.1 munch-2.5.0 pretrainedmodels-0.7.4 segmentation-models-pytorch-0.3.0 timm-0.4.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install lightning-bolts"
      ],
      "metadata": {
        "id": "J5UoeF8bJNmd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "690544cd-c9e4-407e-d580-9779172d556c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting lightning-bolts\n",
            "  Downloading lightning_bolts-0.5.0-py3-none-any.whl (316 kB)\n",
            "\u001b[K     |████████████████████████████████| 316 kB 19.8 MB/s \n",
            "\u001b[?25hCollecting torchmetrics>=0.4.1\n",
            "  Downloading torchmetrics-0.9.3-py3-none-any.whl (419 kB)\n",
            "\u001b[K     |████████████████████████████████| 419 kB 63.1 MB/s \n",
            "\u001b[?25hCollecting pytorch-lightning>=1.4.0\n",
            "  Downloading pytorch_lightning-1.7.1-py3-none-any.whl (701 kB)\n",
            "\u001b[K     |████████████████████████████████| 701 kB 60.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.7.1 in /usr/local/lib/python3.7/dist-packages (from lightning-bolts) (1.12.1+cu113)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from lightning-bolts) (21.3)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning>=1.4.0->lightning-bolts) (1.21.6)\n",
            "Collecting fsspec[http]!=2021.06.0,>=2021.05.0\n",
            "  Downloading fsspec-2022.7.1-py3-none-any.whl (141 kB)\n",
            "\u001b[K     |████████████████████████████████| 141 kB 32.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning>=1.4.0->lightning-bolts) (4.64.0)\n",
            "Collecting pyDeprecate>=0.3.1\n",
            "  Downloading pyDeprecate-0.3.2-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning>=1.4.0->lightning-bolts) (4.1.1)\n",
            "Collecting tensorboard>=2.9.1\n",
            "  Downloading tensorboard-2.10.0-py3-none-any.whl (5.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.9 MB 66.0 MB/s \n",
            "\u001b[?25hCollecting PyYAML>=5.4\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 62.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.4.0->lightning-bolts) (2.23.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.4.0->lightning-bolts) (3.8.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->lightning-bolts) (3.0.9)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch-lightning>=1.4.0->lightning-bolts) (0.4.6)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch-lightning>=1.4.0->lightning-bolts) (1.47.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch-lightning>=1.4.0->lightning-bolts) (1.2.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch-lightning>=1.4.0->lightning-bolts) (3.17.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch-lightning>=1.4.0->lightning-bolts) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch-lightning>=1.4.0->lightning-bolts) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch-lightning>=1.4.0->lightning-bolts) (1.0.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch-lightning>=1.4.0->lightning-bolts) (1.35.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch-lightning>=1.4.0->lightning-bolts) (57.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch-lightning>=1.4.0->lightning-bolts) (3.4.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch-lightning>=1.4.0->lightning-bolts) (0.37.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch-lightning>=1.4.0->lightning-bolts) (0.2.8)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch-lightning>=1.4.0->lightning-bolts) (1.15.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch-lightning>=1.4.0->lightning-bolts) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch-lightning>=1.4.0->lightning-bolts) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.9.1->pytorch-lightning>=1.4.0->lightning-bolts) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.9.1->pytorch-lightning>=1.4.0->lightning-bolts) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.9.1->pytorch-lightning>=1.4.0->lightning-bolts) (3.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch-lightning>=1.4.0->lightning-bolts) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.4.0->lightning-bolts) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.4.0->lightning-bolts) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.4.0->lightning-bolts) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.4.0->lightning-bolts) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.9.1->pytorch-lightning>=1.4.0->lightning-bolts) (3.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.4.0->lightning-bolts) (6.0.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.4.0->lightning-bolts) (22.1.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.4.0->lightning-bolts) (4.0.2)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.4.0->lightning-bolts) (2.1.0)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.4.0->lightning-bolts) (0.13.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.4.0->lightning-bolts) (1.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.4.0->lightning-bolts) (1.8.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.4.0->lightning-bolts) (1.3.1)\n",
            "Installing collected packages: fsspec, torchmetrics, tensorboard, PyYAML, pyDeprecate, pytorch-lightning, lightning-bolts\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.8.0\n",
            "    Uninstalling tensorboard-2.8.0:\n",
            "      Successfully uninstalled tensorboard-2.8.0\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.8.2+zzzcolab20220719082949 requires tensorboard<2.9,>=2.8, but you have tensorboard 2.10.0 which is incompatible.\u001b[0m\n",
            "Successfully installed PyYAML-6.0 fsspec-2022.7.1 lightning-bolts-0.5.0 pyDeprecate-0.3.2 pytorch-lightning-1.7.1 tensorboard-2.10.0 torchmetrics-0.9.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wv9D2zLftM0Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b98e3ece-0fb1-42a3-ce9b-f357d8e381e7"
      },
      "source": [
        "!sudo apt-get install tree -qq > /dev/null"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/NVIDIA/apex && cd apex && pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" . --user && cd .. && rm -rf apex"
      ],
      "metadata": {
        "id": "eUudUgminIqd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34cb804c-6027-4b5a-df40-ece47101077a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'apex'...\n",
            "remote: Enumerating objects: 10117, done.\u001b[K\n",
            "remote: Counting objects: 100% (233/233), done.\u001b[K\n",
            "remote: Compressing objects: 100% (166/166), done.\u001b[K\n",
            "remote: Total 10117 (delta 119), reused 151 (delta 61), pack-reused 9884\u001b[K\n",
            "Receiving objects: 100% (10117/10117), 14.96 MiB | 15.71 MiB/s, done.\n",
            "Resolving deltas: 100% (6924/6924), done.\n",
            "/usr/local/lib/python3.7/dist-packages/pip/_internal/commands/install.py:232: UserWarning: Disabling all use of wheels due to the use of --build-option / --global-option / --install-option.\n",
            "  cmdoptions.check_install_build_global(options)\n",
            "Using pip 21.1.3 from /usr/local/lib/python3.7/dist-packages/pip (python 3.7)\n",
            "User install by explicit request\n",
            "Created temporary directory: /tmp/pip-ephem-wheel-cache-vbqasbif\n",
            "Created temporary directory: /tmp/pip-req-tracker-hyuny0mc\n",
            "Initialized build tracking at /tmp/pip-req-tracker-hyuny0mc\n",
            "Created build tracker: /tmp/pip-req-tracker-hyuny0mc\n",
            "Entered build tracker: /tmp/pip-req-tracker-hyuny0mc\n",
            "Created temporary directory: /tmp/pip-install-x5de2tvk\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Processing /content/apex\n",
            "  Created temporary directory: /tmp/pip-req-build-skjwv_uv\n",
            "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
            "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
            "  Added file:///content/apex to build tracker '/tmp/pip-req-tracker-hyuny0mc'\n",
            "    Running setup.py (path:/tmp/pip-req-build-skjwv_uv/setup.py) egg_info for package from file:///content/apex\n",
            "    Created temporary directory: /tmp/pip-pip-egg-info-gjnv6zn5\n",
            "    Running command python setup.py egg_info\n",
            "\n",
            "\n",
            "    torch.__version__  = 1.12.1+cu113\n",
            "\n",
            "\n",
            "    running egg_info\n",
            "    creating /tmp/pip-pip-egg-info-gjnv6zn5/apex.egg-info\n",
            "    writing /tmp/pip-pip-egg-info-gjnv6zn5/apex.egg-info/PKG-INFO\n",
            "    writing dependency_links to /tmp/pip-pip-egg-info-gjnv6zn5/apex.egg-info/dependency_links.txt\n",
            "    writing top-level names to /tmp/pip-pip-egg-info-gjnv6zn5/apex.egg-info/top_level.txt\n",
            "    writing manifest file '/tmp/pip-pip-egg-info-gjnv6zn5/apex.egg-info/SOURCES.txt'\n",
            "    adding license file 'LICENSE'\n",
            "    writing manifest file '/tmp/pip-pip-egg-info-gjnv6zn5/apex.egg-info/SOURCES.txt'\n",
            "  Source in /tmp/pip-req-build-skjwv_uv has version 0.1, which satisfies requirement apex==0.1 from file:///content/apex\n",
            "  Removed apex==0.1 from file:///content/apex from build tracker '/tmp/pip-req-tracker-hyuny0mc'\n",
            "Created temporary directory: /tmp/pip-unpack-bizpfd4j\n",
            "Skipping wheel build for apex, due to binaries being disabled for it.\n",
            "Installing collected packages: apex\n",
            "  Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "  distutils: /root/.local/include/python3.7m/apex\n",
            "  sysconfig: /root/.local/include/python3.7/apex\n",
            "  Additional context:\n",
            "  user = True\n",
            "  home = None\n",
            "  root = None\n",
            "  prefix = None\n",
            "  Created temporary directory: /tmp/pip-record-_lcoei2e\n",
            "    Running command /usr/bin/python3 -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-req-build-skjwv_uv/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-req-build-skjwv_uv/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' --cpp_ext --cuda_ext install --record /tmp/pip-record-_lcoei2e/install-record.txt --single-version-externally-managed --user --prefix= --compile --install-headers /root/.local/include/python3.7m/apex\n",
            "\n",
            "\n",
            "    torch.__version__  = 1.12.1+cu113\n",
            "\n",
            "\n",
            "\n",
            "    Compiling cuda extensions with\n",
            "    nvcc: NVIDIA (R) Cuda compiler driver\n",
            "    Copyright (c) 2005-2020 NVIDIA Corporation\n",
            "    Built on Mon_Oct_12_20:09:46_PDT_2020\n",
            "    Cuda compilation tools, release 11.1, V11.1.105\n",
            "    Build cuda_11.1.TC455_06.29190527_0\n",
            "    from /usr/local/cuda/bin\n",
            "\n",
            "    Traceback (most recent call last):\n",
            "      File \"<string>\", line 1, in <module>\n",
            "      File \"/tmp/pip-req-build-skjwv_uv/setup.py\", line 175, in <module>\n",
            "        check_cuda_torch_binary_vs_bare_metal(CUDA_HOME)\n",
            "      File \"/tmp/pip-req-build-skjwv_uv/setup.py\", line 38, in check_cuda_torch_binary_vs_bare_metal\n",
            "        + \"In some cases, a minor-version mismatch will not cause later errors:  \"\n",
            "    RuntimeError: Cuda extensions are being compiled with a version of Cuda that does not match the version used to compile Pytorch binaries.  Pytorch binaries were compiled with Cuda 11.3.\n",
            "    In some cases, a minor-version mismatch will not cause later errors:  https://github.com/NVIDIA/apex/pull/323#discussion_r287021798.  You can try commenting out this check (at your own risk).\n",
            "    Running setup.py install for apex ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[31mERROR: Command errored out with exit status 1: /usr/bin/python3 -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-req-build-skjwv_uv/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-req-build-skjwv_uv/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' --cpp_ext --cuda_ext install --record /tmp/pip-record-_lcoei2e/install-record.txt --single-version-externally-managed --user --prefix= --compile --install-headers /root/.local/include/python3.7m/apex Check the logs for full command output.\u001b[0m\n",
            "Exception information:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/req/req_install.py\", line 825, in install\n",
            "    req_description=str(self.req),\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/operations/install/legacy.py\", line 81, in install\n",
            "    raise LegacyInstallFailure\n",
            "pip._internal.operations.install.legacy.LegacyInstallFailure\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/cli/base_command.py\", line 180, in _main\n",
            "    status = self.run(options, args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/cli/req_command.py\", line 199, in wrapper\n",
            "    return func(self, options, args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/commands/install.py\", line 402, in run\n",
            "    pycompile=options.compile,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/req/__init__.py\", line 85, in install_given_reqs\n",
            "    pycompile=pycompile,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/req/req_install.py\", line 829, in install\n",
            "    six.reraise(*exc.parent)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/six.py\", line 703, in reraise\n",
            "    raise value\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/operations/install/legacy.py\", line 71, in install\n",
            "    cwd=unpacked_source_directory,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/utils/subprocess.py\", line 278, in runner\n",
            "    spinner=spinner,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/utils/subprocess.py\", line 244, in call_subprocess\n",
            "    raise InstallationSubprocessError(proc.returncode, command_desc)\n",
            "pip._internal.exceptions.InstallationSubprocessError: Command errored out with exit status 1: /usr/bin/python3 -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-req-build-skjwv_uv/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-req-build-skjwv_uv/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' --cpp_ext --cuda_ext install --record /tmp/pip-record-_lcoei2e/install-record.txt --single-version-externally-managed --user --prefix= --compile --install-headers /root/.local/include/python3.7m/apex Check the logs for full command output.\n",
            "Removed build tracker: '/tmp/pip-req-tracker-hyuny0mc'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ultralytics/yolov5.git"
      ],
      "metadata": {
        "id": "lInLA8Z1vXM4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1738e1fa-c328-4a16-90c8-7f4b3906405f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov5'...\n",
            "remote: Enumerating objects: 12679, done.\u001b[K\n",
            "remote: Counting objects: 100% (61/61), done.\u001b[K\n",
            "remote: Compressing objects: 100% (43/43), done.\u001b[K\n",
            "remote: Total 12679 (delta 33), reused 40 (delta 18), pack-reused 12618\u001b[K\n",
            "Receiving objects: 100% (12679/12679), 12.57 MiB | 32.50 MiB/s, done.\n",
            "Resolving deltas: 100% (8685/8685), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cp /content/drive/MyDrive/ML_models/FinalProject/Weight/burns.yaml /content/yolov5/data/burns.yaml"
      ],
      "metadata": {
        "id": "-zEKy27svfDp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /content/yolov5/inference/"
      ],
      "metadata": {
        "id": "-WP9ZYTmwD_K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cp /content/drive/MyDrive/ML_models/FinalProject/Weight/best_yolo5x640.pt /content/best_yolo5.pt\n",
        "%cp /content/drive/MyDrive/ML_models/FinalProject/Weight/yolov5x.yaml /content/yolov5/models/yolov5x.yaml"
      ],
      "metadata": {
        "id": "zHXDooU_whc_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cp /content/drive/MyDrive/ML_models/FinalProject/Weight/detect.py /content/yolov5/detect.py"
      ],
      "metadata": {
        "id": "8C65FpRmPh9u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8pNi7Tdj875o",
        "outputId": "940c3269-f061-487b-9f6f-2efc215f3c1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/yolov5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EDSYUe2Ddmqd",
        "outputId": "85e016da-61b9-422f-ae2b-5d2194cbf81c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/yolov5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/yolov5/app.py\n",
        "\n",
        "import streamlit as st\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sklearn\n",
        "import torch\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset\n",
        "import albumentations as A\n",
        "from albumentations.augmentations.transforms import Normalize\n",
        "from torchvision import transforms\n",
        "from random import randint\n",
        "from tqdm.notebook import tqdm\n",
        "from sklearn.metrics import classification_report,f1_score,accuracy_score\n",
        "import os.path\n",
        "from skimage.io import imread\n",
        "import os\n",
        "import skimage\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from torchvision.models import efficientnet_b3\n",
        "from torchvision.models import EfficientNet_B3_Weights\n",
        "from PIL import Image\n",
        "import segmentation_models_pytorch as smp\n",
        "import shutil\n",
        "import detect\n",
        "import seaborn as sns\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error,mean_absolute_error\n",
        "from sklearn.ensemble import RandomForestRegressor,AdaBoostRegressor,GradientBoostingRegressor\n",
        "from imblearn.over_sampling import ADASYN\n",
        "import pickle\n",
        "from pl_bolts.models.autoencoders.components import (\n",
        "    resnet18_decoder,\n",
        "    resnet18_encoder,\n",
        ")\n",
        "import pytorch_lightning as pl\n",
        "from torch import nn\n",
        "\n",
        "\n",
        "transform_val=A.Compose([  \n",
        "        A.Resize(256,256),\n",
        "        Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
        "])\n",
        "\n",
        "inv_transform=A.Compose([\n",
        "    Normalize(mean=[-0.485/0.229,-0.456/0.224,-0.406/0.225],std=[1/0.229,1/0.224,1/0.225],max_pixel_value=1)\n",
        "])\n",
        "\n",
        "load_transform=transforms.Compose([\n",
        "    transforms.Resize((256,256))\n",
        "])\n",
        "transform_vae=transforms.Compose([\n",
        "                     transforms.Resize((128,128)),\n",
        "                     transforms.ToTensor()          \n",
        "])\n",
        "\n",
        "def check_anomalies(network,img,th):\n",
        "    network.eval()\n",
        "    \n",
        "    #img = PIL.Image.open(f\"/content/anomalies/{f}\")\n",
        "    img_transform=transform_vae(img)\n",
        "    t_img=torch.unsqueeze(img_transform,0)\n",
        "    t_img=t_img.cuda()\n",
        "            \n",
        "    trans=network(t_img)\n",
        "    mae_error = np.mean(np.abs(trans[0][0].detach().cpu().numpy()- t_img.cpu().numpy()))\n",
        "    if mae_error>=th:\n",
        "        return \"anomaly\"\n",
        "    else:\n",
        "        return \"no anomaly\" \n",
        "    return 0\n",
        "\n",
        "classes={\n",
        "    0:\"actinic keratosis\",\n",
        "    1:\"basal cell carcinoma\",\n",
        "    2:\"dermatofibroma\",\n",
        "    3:\"melanoma\",\n",
        "    4:\"nevus\",\n",
        "    5:\"pigmented benign keratosis\",\n",
        "    6:\"seborrheic keratosis\",\n",
        "    7:\"squamous cell carcinoma\",\n",
        "    8:\"vascular lesion\"\n",
        "}\n",
        "\n",
        "class VAE(torch.nn.Module):\n",
        "    def __init__(self, enc_out_dim=512, latent_dim=256, input_height=128):\n",
        "        super(VAE,self).__init__()\n",
        "        self.encoder = resnet18_encoder(False, False)\n",
        "        self.decoder = resnet18_decoder(\n",
        "            latent_dim=latent_dim,\n",
        "            input_height=input_height,\n",
        "            first_conv=False,\n",
        "            maxpool1=False\n",
        "        )\n",
        "        self.fc_mu = torch.nn.Linear(enc_out_dim, latent_dim)\n",
        "        self.fc_var = torch.nn.Linear(enc_out_dim, latent_dim)\n",
        "\n",
        "    def forward(self,batch):\n",
        "\n",
        "        x_encoded = self.encoder(batch)\n",
        "\n",
        "        mu, log_var = self.fc_mu(x_encoded), self.fc_var(x_encoded) \n",
        "\n",
        "        std = torch.exp(log_var / 2)\n",
        "        q = torch.distributions.Normal(mu, std)\n",
        "        z = q.rsample() \n",
        "        \n",
        "        # reconstruction = self.decoder(z)\n",
        "        x = self.decoder(z)\n",
        "        reconstruction = torch.sigmoid(x)\n",
        "        return reconstruction,mu,log_var\n",
        "\n",
        "class MyEfficientnet(torch.nn.Module):\n",
        "    def __init__(self,network):\n",
        "        super(MyEfficientnet,self).__init__()\n",
        "        self.fc1=torch.nn.Linear(1536,128)\n",
        "        self.fc2=torch.nn.Linear(128,9)\n",
        "        self.network=network\n",
        "\n",
        "        self.dropout=torch.nn.Dropout(0.4)\n",
        "        self.bn1=torch.nn.BatchNorm1d(128)\n",
        "        self.relu=torch.nn.ReLU()\n",
        "\n",
        "    def forward(self,x):\n",
        "        x=self.network(x)\n",
        "        x=self.dropout(self.relu(self.bn1(self.fc1(x))))\n",
        "        x=self.fc2(x)\n",
        "        return x\n",
        "\n",
        "@st.cache(allow_output_mutation=True)\n",
        "\n",
        "def load_model():\n",
        "    efficientnet = efficientnet_b3(weights=EfficientNet_B3_Weights.IMAGENET1K_V1)\n",
        "    efficientnet.classifier=torch.nn.Sequential(*list(efficientnet.classifier.children())[:-1])\n",
        "    state=torch.load(\"/content/drive/MyDrive/ML_models/FinalProject/Weight/MyEfficientnet_256_best_model.pt\")\n",
        "    model=MyEfficientnet(efficientnet).cuda()\n",
        "    model.load_state_dict(state['state_dict'])\n",
        "\n",
        "    return model\n",
        "\n",
        "def load_seg_model():\n",
        "    seg_model=smp.Unet(encoder_name=\"resnet18\",encoder_depth=5,encoder_weights='imagenet',\n",
        "                          decoder_channels=(256, 128, 64, 32, 16),decoder_use_batchnorm=True,\n",
        "                          in_channels=3,classes=1,activation=None\n",
        "                          ).cuda()\n",
        "    state=torch.load(\"/content/drive/MyDrive/ML_models/FinalProject/Weight/UnetResNet18_best_model.pt\")\n",
        "    seg_model.load_state_dict(state['state_dict'])\n",
        "    return seg_model\n",
        "\n",
        "def load_tumor_model():\n",
        "    with open('/content/drive/MyDrive/ML_models/FinalProject/Weight/table.pickle', 'rb') as f:\n",
        "        tumor_model=pickle.load(f)\n",
        "    return tumor_model\n",
        "\n",
        "def load_vae_model():\n",
        "    state=torch.load(\"/content/drive/MyDrive/ML_models/FinalProject/Weight/vae_new_model_best_model.pt\")\n",
        "    best_model=VAE().cuda()\n",
        "    best_model.load_state_dict(state['state_dict'])\n",
        "    return best_model\n",
        "\n",
        "with st.spinner('Models is being loaded..'):\n",
        "    model=load_model()\n",
        "    seg_model=load_seg_model()\n",
        "    tumor_model=load_tumor_model()\n",
        "    vae_model=load_vae_model()\n",
        "\n",
        "if \"image_number\" not in st.session_state:\n",
        "    st.session_state[\"image_number\"]=1\n",
        "\n",
        "st.write(\"\"\"\n",
        "         # Medical application\n",
        "         \"\"\"\n",
        "         )\n",
        "\n",
        "page_name=['Identify a mole','Determine the location and degree of burn','Predict tumor size']\n",
        "page=st.radio('Navigation',page_name)\n",
        "\n",
        "if page==\"Identify a mole\" or page == \"Determine the location and degree of burn\":\n",
        "    file = st.file_uploader(\"Please upload an image\", type=[\"jpg\", \"png\"])\n",
        "\n",
        "if page == \"Predict tumor size\":\n",
        "    mass_npea=st.sidebar.number_input(\"mass_npea\",key=\"Mass_npea\")\n",
        "    size_npear=st.sidebar.number_input(\"size_npear\",key=\"Size_npear\")\n",
        "    malign_ratio=st.sidebar.number_input(\"malign_ratio\",key=\"Malign_ratio\")\n",
        "    damage_size=st.sidebar.number_input(\"damage_size\",key=\"Damage_size\")\n",
        "    exposed_area=st.sidebar.number_input(\"exposed_area\",key=\"Exposed_area\")\n",
        "    std_dev_malign=st.sidebar.number_input(\"std_dev_malign\",key=\"Std_dev_malign\")\n",
        "    err_malign=st.sidebar.number_input(\"err_malign\",key=\"Err_malign\")\n",
        "    malign_penalty=st.sidebar.number_input(\"malign_penalty\",key=\"Malign_penalty\")\n",
        "    damage_ratio=st.sidebar.number_input(\"damage_ratio\",key=\"Damage_ratio\")\n",
        "    data={\n",
        "        \"mass_npea\":mass_npea,\n",
        "        \"size_npear\":size_npear,\n",
        "        \"malign_ratio\":malign_ratio,\n",
        "        \"damage_size\":damage_size,\n",
        "        \"exposed_area\":exposed_area,\n",
        "        \"std_dev_malign\":std_dev_malign,\n",
        "        \"err_malign\":err_malign,\n",
        "        \"malign_penalty\":malign_penalty,\n",
        "        \"damage_ratio\":damage_ratio\n",
        "\n",
        "    }\n",
        "    df=pd.DataFrame(data,index=[0])\n",
        "    st.subheader(\"User Input parameters\")\n",
        "    st.write(df)\n",
        "    prediction=tumor_model.predict(df)\n",
        "    st.subheader(\"tumor size\")\n",
        "    st.write(prediction)   \n",
        "\n",
        "def predict_cancer(img, model):\n",
        "    model.eval()\n",
        "\n",
        "    img=np.array(img)\n",
        "    transformed=transform_val(image=img)\n",
        "    t_img=torch.tensor(np.transpose(transformed['image'],(2,0,1)))\n",
        "    t_img=torch.unsqueeze(t_img,0)\n",
        "    t_img=t_img.cuda()\n",
        "\n",
        "    y_predicted=model(t_img)\n",
        "    return y_predicted\n",
        "\n",
        "def predict_mask(network,img):\n",
        "    network.eval()\n",
        "\n",
        "    img=np.array(img)\n",
        "    transformed=transform_val(image=img)\n",
        "    t_img=torch.tensor(np.transpose(transformed['image'],(2,0,1)))\n",
        "    t_img=torch.unsqueeze(t_img,0)\n",
        "    t_img=t_img.cuda()\n",
        "\n",
        "    mask_pred=network(t_img)\n",
        "\n",
        "    return mask_pred\n",
        "\n",
        "if page==\"Identify a mole\" or page == \"Determine the location and degree of burn\":\n",
        "    if file is None:\n",
        "        pass\n",
        "    else:\n",
        "        if \"nav\" not in st.session_state:\n",
        "            if page==\"Identify a mole\":\n",
        "                st.session_state[\"nav\"]=1\n",
        "            elif page==\"Determine the location and degree of burn\":\n",
        "                st.session_state[\"nav\"]=2\n",
        "\n",
        "if page==\"Identify a mole\" or page == \"Determine the location and degree of burn\":\n",
        "    if file is None:\n",
        "    #    st.text(\"Please upload an image file\")\n",
        "        pass\n",
        "    else:\n",
        "        if page==\"Identify a mole\":\n",
        "            if st.session_state[\"nav\"]==1:\n",
        "                image = Image.open(file)\n",
        "\n",
        "                res=check_anomalies(vae_model,image,0.15)\n",
        "                if res == \"no anomaly\":\n",
        "\n",
        "                    with st.spinner('Makeing predictions..'):\n",
        "                        prediction = predict_cancer(image, model)\n",
        "                    ind=torch.argmax(prediction,axis=1).detach().cpu().numpy()[0]\n",
        "                    st.image(load_transform(image),caption=classes[ind])\n",
        "\n",
        "                    with st.spinner('Makeing mask..'):\n",
        "                        mask=predict_mask(seg_model,image)\n",
        "                    mask=torch.squeeze(mask)\n",
        "                    mask=mask>-0.3\n",
        "                    mask=mask.byte()\n",
        "                    mask=mask.detach().to('cpu').numpy()\n",
        "\n",
        "                    pil_img=Image.fromarray(mask*255,mode=\"L\")\n",
        "                    st.image(pil_img,caption='lesion')\n",
        "\n",
        "                    if classes[ind]==\"melanoma\":\n",
        "                        st.write(\"Melanoma is a form of skin cancer that begins in the cells (melanocytes) that control the pigment in your skin. Melanoma is the most invasive skin cancer with the highest risk of death. While it's a serious skin cancer, it's highly curable if caught early. Prevention and early treatment are critical, especially if you have fair skin, blonde or red hair and blue eyes.\")\n",
        "                    elif classes[ind]==\"actinic keratosis\":\n",
        "                        st.write(\"Actinic keratoses (also called solar keratoses) are dry scaly patches of skin that have been damaged by the sun. The patches are not usually serious. But there's a small chance they could become skin cancer, so it's important to avoid further damage to your skin.\")\n",
        "                    elif classes[ind]==\"basal cell carcinoma\":\n",
        "                        st.write(\"Basal cell carcinoma is a type of skin cancer that most often develops on areas of skin exposed to the sun, such as the face. On brown and Black skin, basal cell carcinoma often looks like a bump that's brown or glossy black and has a rolled border. Basal cell carcinoma is a type of skin cancer.\")\n",
        "                    elif classes[ind]==\"dermatofibroma\":\n",
        "                        st.write(\"A cellular dermatofibroma is a noncancerous skin growth. It may look like a small, firm bump, similar to a mole. Unlike other dermatofibromas, cellular dermatofibromas often attach to your deepest layer of skin. Because they're noncancerous, they usually don't need treatment\")\n",
        "                    elif classes[ind]==\"nevus\":\n",
        "                        st.write(\"Nevus is a benign (not cancer) growth on the skin that is formed by a cluster of melanocytes (cells that make a substance called melanin, which gives color to skin and eyes). A nevus is usually dark and may be raised from the skin.\")\n",
        "                    elif classes[ind]==\"pigmented benign keratosis\":\n",
        "                        st.write(\"Pigmented actinic keratosis is a variant of actinic keratosis that occurs less commonly. In contrast to presenting as an erythematous plaque, its appearance can mimic a pigmented lesion (lentigo maligna or solar lentigo) or a keratinocytic lesion (lichen planus-like keratosis).\")\n",
        "                    elif classes[ind]==\"seborrheic keratosis\":\n",
        "                        st.write(\"A seborrheic keratosis (seb-o-REE-ik ker-uh-TOE-sis) is a common noncancerous (benign) skin growth. People tend to get more of them as they get older. Seborrheic keratoses are usually brown, black or light tan. The growths (lesions) look waxy or scaly and slightly raised\")\n",
        "                    elif classes[ind]==\"squamous cell carcinoma\":\n",
        "                        st.write(\"Squamous cell carcinoma of the skin is a common form of skin cancer that develops in the squamous cells that make up the middle and outer layers of the skin. Squamous cell carcinoma of the skin is usually not life-threatening, though it can be aggressive.\")\n",
        "                    elif classes[ind]==\"vascular lesion\":\n",
        "                        st.write(\"Vascular lesions are relatively common abnormalities of the skin and underlying tissues, more commonly known as birthmarks.Vascular tumors may be benign (not cancer) or malignant (cancer) and can occur anywhere in the body. They may form on the skin, in the tissues below the skin, and/or in an organ. There are many types of vascular tumors.\")\n",
        "                else:\n",
        "                    st.write(\"This isn't mole. Upload another image\")            \n",
        "            else:\n",
        "                st.session_state[\"nav\"]=1\n",
        "        if page==\"Determine the location and degree of burn\":\n",
        "            if st.session_state[\"nav\"]==2:\n",
        "                image = Image.open(file)\n",
        "                \n",
        "                im_number=st.session_state[\"image_number\"]\n",
        "\n",
        "                os.mkdir(f\"/content/yolov5/inference/image_{im_number}\")\n",
        "\n",
        "                im1 = image.save(f\"/content/yolov5/inference/image_{im_number}/burn_image.jpg\")\n",
        "\n",
        "                weights=\"/content/best_yolo5.pt\"\n",
        "                imgsz=(640,640)\n",
        "                conf_thres=0.15\n",
        "                source=f\"/content/yolov5/inference/image_{im_number}\"\n",
        "\n",
        "                return_path=detect.main_1(weights,source,imgsz,conf_thres)\n",
        "                det_image=Image.open(f\"/content/yolov5/{return_path}/burn_image.jpg\")\n",
        "                st.image(det_image)\n",
        "                st.session_state[\"image_number\"]+=1\n",
        "            else:\n",
        "                st.session_state[\"nav\"]=2\n",
        "st.write(\"Done\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxIdddiCVMSz",
        "outputId": "16737f4f-9817-440f-9723-1f29869b35dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing /content/yolov5/app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app.py & npx localtunnel --port 8501"
      ],
      "metadata": {
        "id": "iRfg2u1WcY7V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2458c677-805c-4fa6-8af0-7cf131941993"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-08-13 18:26:16.466 INFO    numexpr.utils: NumExpr defaulting to 2 threads.\n",
            "\u001b[K\u001b[?25hnpx: installed 22 in 1.898s\n",
            "your url is: https://chilly-planes-notice-34-86-170-47.loca.lt\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.2:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.86.170.47:8501\u001b[0m\n",
            "\u001b[0m\n",
            "2022-08-13 18:26:33.131 Created a temporary directory at /tmp/tmpcvk1go8z\n",
            "Created a temporary directory at /tmp/tmpcvk1go8z\n",
            "2022-08-13 18:26:33.132 Writing /tmp/tmpcvk1go8z/_remote_module_non_scriptable.py\n",
            "Writing /tmp/tmpcvk1go8z/_remote_module_non_scriptable.py\n",
            "2022-08-13 18:33:31.022 \u001b[34m\u001b[1mdetect: \u001b[0mweights=yolov5s.pt, source=data/images, data=data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False\n",
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=yolov5s.pt, source=data/images, data=data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False\n",
            "2022-08-13 18:33:31.264 YOLOv5 🚀 v6.1-389-g6aed0a7 Python-3.7.13 torch-1.12.1+cu113 CUDA:0 (Tesla T4, 15110MiB)\n",
            "\n",
            "YOLOv5 🚀 v6.1-389-g6aed0a7 Python-3.7.13 torch-1.12.1+cu113 CUDA:0 (Tesla T4, 15110MiB)\n",
            "\n",
            "2022-08-13 18:33:31.485 Fusing layers... \n",
            "Fusing layers... \n",
            "2022-08-13 18:33:32.203 YOLOv5x summary: 444 layers, 86186872 parameters, 0 gradients\n",
            "YOLOv5x summary: 444 layers, 86186872 parameters, 0 gradients\n",
            "2022-08-13 18:33:32.867 WARNING: NMS time limit 0.330s exceeded\n",
            "WARNING: NMS time limit 0.330s exceeded\n",
            "2022-08-13 18:33:32.871 image 1/1 /content/yolov5/inference/image_1/burn_image.jpg: 512x640 1 first_degree, Done. (0.074s)\n",
            "image 1/1 /content/yolov5/inference/image_1/burn_image.jpg: 512x640 1 first_degree, Done. (0.074s)\n",
            "2022-08-13 18:33:32.871 Speed: 0.7ms pre-process, 74.2ms inference, 489.9ms NMS per image at shape (1, 3, 640, 640)\n",
            "Speed: 0.7ms pre-process, 74.2ms inference, 489.9ms NMS per image at shape (1, 3, 640, 640)\n",
            "2022-08-13 18:33:32.872 Results saved to \u001b[1mruns/detect/exp4\u001b[0m\n",
            "Results saved to \u001b[1mruns/detect/exp4\u001b[0m\n",
            "2022-08-13 18:33:47.577 \u001b[34m\u001b[1mdetect: \u001b[0mweights=yolov5s.pt, source=data/images, data=data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False\n",
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=yolov5s.pt, source=data/images, data=data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False\n",
            "2022-08-13 18:33:47.705 YOLOv5 🚀 v6.1-389-g6aed0a7 Python-3.7.13 torch-1.12.1+cu113 CUDA:0 (Tesla T4, 15110MiB)\n",
            "\n",
            "YOLOv5 🚀 v6.1-389-g6aed0a7 Python-3.7.13 torch-1.12.1+cu113 CUDA:0 (Tesla T4, 15110MiB)\n",
            "\n",
            "2022-08-13 18:33:47.925 Fusing layers... \n",
            "Fusing layers... \n",
            "2022-08-13 18:33:48.634 YOLOv5x summary: 444 layers, 86186872 parameters, 0 gradients\n",
            "YOLOv5x summary: 444 layers, 86186872 parameters, 0 gradients\n",
            "2022-08-13 18:33:48.793 image 1/1 /content/yolov5/inference/image_2/burn_image.jpg: 352x640 1 first_degree, 1 second_degree, 1 third_degree, Done. (0.050s)\n",
            "image 1/1 /content/yolov5/inference/image_2/burn_image.jpg: 352x640 1 first_degree, 1 second_degree, 1 third_degree, Done. (0.050s)\n",
            "2022-08-13 18:33:48.794 Speed: 0.4ms pre-process, 49.5ms inference, 1.1ms NMS per image at shape (1, 3, 640, 640)\n",
            "Speed: 0.4ms pre-process, 49.5ms inference, 1.1ms NMS per image at shape (1, 3, 640, 640)\n",
            "2022-08-13 18:33:48.794 Results saved to \u001b[1mruns/detect/exp5\u001b[0m\n",
            "Results saved to \u001b[1mruns/detect/exp5\u001b[0m\n",
            "2022-08-13 18:34:19.007 \u001b[34m\u001b[1mdetect: \u001b[0mweights=yolov5s.pt, source=data/images, data=data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False\n",
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=yolov5s.pt, source=data/images, data=data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False\n",
            "2022-08-13 18:34:19.135 YOLOv5 🚀 v6.1-389-g6aed0a7 Python-3.7.13 torch-1.12.1+cu113 CUDA:0 (Tesla T4, 15110MiB)\n",
            "\n",
            "YOLOv5 🚀 v6.1-389-g6aed0a7 Python-3.7.13 torch-1.12.1+cu113 CUDA:0 (Tesla T4, 15110MiB)\n",
            "\n",
            "2022-08-13 18:34:19.351 Fusing layers... \n",
            "Fusing layers... \n",
            "2022-08-13 18:34:20.088 YOLOv5x summary: 444 layers, 86186872 parameters, 0 gradients\n",
            "YOLOv5x summary: 444 layers, 86186872 parameters, 0 gradients\n",
            "2022-08-13 18:34:20.273 image 1/1 /content/yolov5/inference/image_3/burn_image.jpg: 448x640 1 second_degree, Done. (0.073s)\n",
            "image 1/1 /content/yolov5/inference/image_3/burn_image.jpg: 448x640 1 second_degree, Done. (0.073s)\n",
            "2022-08-13 18:34:20.273 Speed: 0.7ms pre-process, 72.9ms inference, 1.4ms NMS per image at shape (1, 3, 640, 640)\n",
            "Speed: 0.7ms pre-process, 72.9ms inference, 1.4ms NMS per image at shape (1, 3, 640, 640)\n",
            "2022-08-13 18:34:20.274 Results saved to \u001b[1mruns/detect/exp6\u001b[0m\n",
            "Results saved to \u001b[1mruns/detect/exp6\u001b[0m\n",
            "2022-08-13 18:34:35.596 \u001b[34m\u001b[1mdetect: \u001b[0mweights=yolov5s.pt, source=data/images, data=data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False\n",
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=yolov5s.pt, source=data/images, data=data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False\n",
            "2022-08-13 18:34:35.725 YOLOv5 🚀 v6.1-389-g6aed0a7 Python-3.7.13 torch-1.12.1+cu113 CUDA:0 (Tesla T4, 15110MiB)\n",
            "\n",
            "YOLOv5 🚀 v6.1-389-g6aed0a7 Python-3.7.13 torch-1.12.1+cu113 CUDA:0 (Tesla T4, 15110MiB)\n",
            "\n",
            "2022-08-13 18:34:35.938 Fusing layers... \n",
            "Fusing layers... \n",
            "2022-08-13 18:34:36.663 YOLOv5x summary: 444 layers, 86186872 parameters, 0 gradients\n",
            "YOLOv5x summary: 444 layers, 86186872 parameters, 0 gradients\n",
            "2022-08-13 18:34:36.827 image 1/1 /content/yolov5/inference/image_4/burn_image.jpg: 480x640 1 second_degree, Done. (0.060s)\n",
            "image 1/1 /content/yolov5/inference/image_4/burn_image.jpg: 480x640 1 second_degree, Done. (0.060s)\n",
            "2022-08-13 18:34:36.828 Speed: 0.5ms pre-process, 59.8ms inference, 1.4ms NMS per image at shape (1, 3, 640, 640)\n",
            "Speed: 0.5ms pre-process, 59.8ms inference, 1.4ms NMS per image at shape (1, 3, 640, 640)\n",
            "2022-08-13 18:34:36.828 Results saved to \u001b[1mruns/detect/exp7\u001b[0m\n",
            "Results saved to \u001b[1mruns/detect/exp7\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:444: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
            "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# for add,d,files in os.walk(\"/content/yolov5/runs/detect\"):\n",
        "#     for f in files:\n",
        "#         os.remove(f\"{add}/burn_image.jpg\")"
      ],
      "metadata": {
        "id": "EjZiKXnLzvP_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# for add,ds,files in os.walk(\"/content/yolov5/runs/detect\"):\n",
        "#     for d in ds:\n",
        "#         os.rmdir(f\"/content/yolov5/runs/detect/{d}\")\n",
        "#     break"
      ],
      "metadata": {
        "id": "ylBJmelr-bq8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "for add,d,files in os.walk(\"/content/yolov5/inference\"):\n",
        "    for f in files:\n",
        "        if f.endswith(\"jpg\"):\n",
        "            os.remove(f\"{add}/burn_image.jpg\")"
      ],
      "metadata": {
        "id": "8mZJisVkR74F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "for add,dirs,files in os.walk(\"/content/yolov5/inference\"):\n",
        "    for dir in dirs:\n",
        "        os.rmdir(f\"{add}/{dir}\")"
      ],
      "metadata": {
        "id": "u2GzVWhISdj_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}